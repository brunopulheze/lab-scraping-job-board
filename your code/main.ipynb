{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import quote_plus\n",
    "from requests.exceptions import RequestException\n",
    "import time\n",
    "import re\n",
    "\n",
    "def scrape_linkedin_job_search(\n",
    "    keywords,\n",
    "    num_pages=1,\n",
    "    country=None,\n",
    "    num_days=None,\n",
    "    pause=1.0,\n",
    "    timeout=10,\n",
    "    fetch_seniority=False,\n",
    "    per_job_pause=0.5,\n",
    "):\n",
    "    # Base URL (let requests handle query params)\n",
    "    BASE_URL = \"https://www.linkedin.com/jobs/search/\"\n",
    "\n",
    "    # Build base params. Let requests encode them; don't pre-encode spaces.\n",
    "    params_base = {\"keywords\": keywords}\n",
    "    if country:\n",
    "        # LinkedIn accepts a plain location string; geoId is more reliable but not public.\n",
    "        params_base[\"location\"] = country\n",
    "    if num_days is not None and isinstance(num_days, (int, float)) and num_days > 0:\n",
    "        seconds = int(num_days * 86400)\n",
    "        params_base[\"f_TPR\"] = f\"r{seconds}\"\n",
    "\n",
    "    # Headers to look like a browser\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    def extract_job_id_and_url(card):\n",
    "        job_id = None\n",
    "        job_url = None\n",
    "        link = card.select_one(\"a.base-card__full-link\") or card.find(\"a\")\n",
    "        if link and link.get(\"href\"):\n",
    "            job_url = link.get(\"href\")\n",
    "            m = re.search(r\"/jobs/view/(\\d+)\", job_url)\n",
    "            if m:\n",
    "                job_id = m.group(1)\n",
    "            else:\n",
    "                m = re.search(r\"currentJobId=(\\d+)\", job_url)\n",
    "                if m:\n",
    "                    job_id = m.group(1)\n",
    "        if not job_id:\n",
    "            urn = card.get(\"data-entity-urn\") or card.get(\"data-urn\")\n",
    "            if urn:\n",
    "                m = re.search(r\"urn:li:jobPosting:(\\d+)\", urn)\n",
    "                if m:\n",
    "                    job_id = m.group(1)\n",
    "        if not job_id:\n",
    "            # Other possible attributes\n",
    "            for attr in (\"data-id\", \"data-job-id\", \"data-job-id\"):  # duplicates okay\n",
    "                if card.get(attr) and str(card.get(attr)).isdigit():\n",
    "                    job_id = str(card.get(attr))\n",
    "                    break\n",
    "        return job_id, job_url\n",
    "\n",
    "    def fetch_job_seniority(session, job_id, job_url):\n",
    "        # Prefer the discovered URL; otherwise, build from job_id\n",
    "        url = job_url or (f\"https://www.linkedin.com/jobs/view/{job_id}/\" if job_id else None)\n",
    "        if not url:\n",
    "            return None\n",
    "        try:\n",
    "            resp = session.get(url, headers=headers, timeout=timeout)\n",
    "        except RequestException:\n",
    "            return None\n",
    "        if resp.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        # Newer markup: description__job-criteria\n",
    "        for li in soup.select(\"li.description__job-criteria-item\"):\n",
    "            header = li.select_one(\"h3\")\n",
    "            value = li.select_one(\"span.description__job-criteria-text, span.job-criteria__text\")\n",
    "            if header and \"seniority\" in header.get_text(strip=True).lower():\n",
    "                return value.get_text(strip=True) if value else None\n",
    "\n",
    "        # Older markup: job-criteria__item\n",
    "        for li in soup.select(\"li.job-criteria__item\"):\n",
    "            header = li.select_one(\"h3.job-criteria__subheader\") or li.find(\"h3\")\n",
    "            value = li.select_one(\"span.job-criteria__text\")\n",
    "            if header and \"seniority\" in header.get_text(strip=True).lower():\n",
    "                return value.get_text(strip=True) if value else None\n",
    "\n",
    "        # Fallback: search for any element mentioning Seniority\n",
    "        text_hit = soup.find(string=lambda t: isinstance(t, str) and \"seniority\" in t.lower())\n",
    "        if text_hit:\n",
    "            # Try the parent block\n",
    "            parent = text_hit.parent\n",
    "            if parent:\n",
    "                nxt = parent.find_next(string=True)\n",
    "                if isinstance(nxt, str) and nxt.strip() and \"seniority\" not in nxt.lower():\n",
    "                    return nxt.strip()\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    session = requests.Session()\n",
    "\n",
    "    for page in range(max(1, int(num_pages))):\n",
    "        params = dict(params_base)\n",
    "        # LinkedIn paginates with 'start' offset of 25 per page\n",
    "        params[\"start\"] = page * 25\n",
    "        try:\n",
    "            resp = session.get(BASE_URL, params=params, headers=headers, timeout=timeout)\n",
    "        except RequestException as e:\n",
    "            print(f\"Request error on page {page+1}: {e}\")\n",
    "            break\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            # 999/403 are common when blocked\n",
    "            print(f\"HTTP {resp.status_code} for page {page+1}. Anti-bot likely. Stopping.\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        # Try current selectors (as of recent LinkedIn markup). Fallback to old selectors if needed\n",
    "        cards = soup.select(\"div.base-card\")\n",
    "        if not cards:\n",
    "            cards = soup.select(\"div.result-card__contents\")\n",
    "\n",
    "        if not cards:\n",
    "            print(f\"No job cards found on page {page+1}. HTML changed or blocked.\")\n",
    "            break\n",
    "\n",
    "        for card in cards:\n",
    "            # Extract fields\n",
    "            title_el = card.select_one(\"h3.base-search-card__title\") or card.find(\"h3\")\n",
    "            company_el = card.select_one(\"h4.base-search-card__subtitle\") or card.find(\"h4\")\n",
    "            location_el = card.select_one(\"span.job-search-card__location\") or card.find(\n",
    "                \"span\", attrs={\"class\": \"job-result-card__location\"}\n",
    "            )\n",
    "\n",
    "            title = title_el.get_text(strip=True) if title_el else None\n",
    "            company = company_el.get_text(strip=True) if company_el else None\n",
    "            location = location_el.get_text(strip=True) if location_el else None\n",
    "\n",
    "            job_id, job_url = extract_job_id_and_url(card)\n",
    "            seniority = None\n",
    "            if fetch_seniority:\n",
    "                seniority = fetch_job_seniority(session, job_id, job_url)\n",
    "                time.sleep(max(0.0, float(per_job_pause)))\n",
    "\n",
    "            if any([title, company, location, job_id]):\n",
    "                rows.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location,\n",
    "                    \"JobId\": job_id,\n",
    "                    \"JobUrl\": job_url,\n",
    "                    \"SeniorityLevel\": seniority,\n",
    "                })\n",
    "\n",
    "        # Be polite; avoid hammering\n",
    "        time.sleep(max(0.0, float(pause)))\n",
    "\n",
    "    # Build DataFrame with optional columns\n",
    "    columns = [\"Title\", \"Company\", \"Location\", \"JobId\", \"JobUrl\", \"SeniorityLevel\"]\n",
    "    data = pd.DataFrame(rows, columns=columns) if rows else pd.DataFrame(columns=columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobId</th>\n",
       "      <th>JobUrl</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst, Disney Advertising Data and Meas...</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>4294362961</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>James Search Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>4294394193</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>TechnoSphere, Inc.</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>4292789745</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-da...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Tech Consulting</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>4294061386</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data &amp; Analytics Intern</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>4294308298</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analyt...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                  Company  \\\n",
       "0  Data Analyst, Disney Advertising Data and Meas...  The Walt Disney Company   \n",
       "1                                       Data Analyst       James Search Group   \n",
       "2                              Business Data Analyst       TechnoSphere, Inc.   \n",
       "3                                Junior Data Analyst          Tech Consulting   \n",
       "4                            Data & Analytics Intern                    Lensa   \n",
       "\n",
       "               Location       JobId  \\\n",
       "0      Santa Monica, CA  4294362961   \n",
       "1         United States  4294394193   \n",
       "2  Texas, United States  4292789745   \n",
       "3            Boston, MA  4294061386   \n",
       "4             Plano, TX  4294308298   \n",
       "\n",
       "                                              JobUrl SeniorityLevel  \n",
       "0  https://www.linkedin.com/jobs/view/data-analys...           None  \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...           None  \n",
       "2  https://www.linkedin.com/jobs/view/business-da...           None  \n",
       "3  https://www.linkedin.com/jobs/view/junior-data...           None  \n",
       "4  https://www.linkedin.com/jobs/view/data-analyt...           None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "results = scrape_linkedin_job_search('data analysis', num_pages=1)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows returned: 294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobId</th>\n",
       "      <th>JobUrl</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst, Disney Advertising Data and Meas...</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>4294362961</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>James Search Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>4294394193</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>TechnoSphere, Inc.</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>4292789745</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-da...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Tech Consulting</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>4294061386</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data &amp; Analytics Intern</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>4294308298</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analyt...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pentangle Tech Services | P5 Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>4294378520</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Intracruit Solutions</td>\n",
       "      <td>Dallas-Fort Worth Metroplex</td>\n",
       "      <td>4294392103</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analytics Intern</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Indianapolis, IN</td>\n",
       "      <td>4294308348</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analyt...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer Intern</td>\n",
       "      <td>ProArch</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>4294342548</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DATA SCIENCE INTERNSHIP</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Tallahassee, FL</td>\n",
       "      <td>4294306797</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scienc...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Analyst, Disney Advertising Data and Meas...   \n",
       "1                                       Data Analyst   \n",
       "2                              Business Data Analyst   \n",
       "3                                Junior Data Analyst   \n",
       "4                            Data & Analytics Intern   \n",
       "5                                       Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                              Data Analytics Intern   \n",
       "8                               Data Engineer Intern   \n",
       "9                            DATA SCIENCE INTERNSHIP   \n",
       "\n",
       "                              Company                     Location  \\\n",
       "0             The Walt Disney Company             Santa Monica, CA   \n",
       "1                  James Search Group                United States   \n",
       "2                  TechnoSphere, Inc.         Texas, United States   \n",
       "3                     Tech Consulting                   Boston, MA   \n",
       "4                               Lensa                    Plano, TX   \n",
       "5  Pentangle Tech Services | P5 Group                United States   \n",
       "6                Intracruit Solutions  Dallas-Fort Worth Metroplex   \n",
       "7                               Lensa             Indianapolis, IN   \n",
       "8                             ProArch                  Atlanta, GA   \n",
       "9                               Lensa              Tallahassee, FL   \n",
       "\n",
       "        JobId                                             JobUrl  \\\n",
       "0  4294362961  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "1  4294394193  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "2  4292789745  https://www.linkedin.com/jobs/view/business-da...   \n",
       "3  4294061386  https://www.linkedin.com/jobs/view/junior-data...   \n",
       "4  4294308298  https://www.linkedin.com/jobs/view/data-analyt...   \n",
       "5  4294378520  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "6  4294392103  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "7  4294308348  https://www.linkedin.com/jobs/view/data-analyt...   \n",
       "8  4294342548  https://www.linkedin.com/jobs/view/data-engine...   \n",
       "9  4294306797  https://www.linkedin.com/jobs/view/data-scienc...   \n",
       "\n",
       "  SeniorityLevel  \n",
       "0           None  \n",
       "1           None  \n",
       "2           None  \n",
       "3           None  \n",
       "4           None  \n",
       "5           None  \n",
       "6           None  \n",
       "7           None  \n",
       "8           None  \n",
       "9           None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "keywords = 'data analysis'\n",
    "\n",
    "# Increase pause a bit to be polite and reduce blocking risk\n",
    "results_5 = scrape_linkedin_job_search(keywords, num_pages=5, pause=1.5, timeout=12)\n",
    "\n",
    "print(f\"Total rows returned: {len(results_5)}\")\n",
    "results_5.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challenge 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Portugal | Total rows: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobId</th>\n",
       "      <th>JobUrl</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior consumer insight Analyst</td>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Lisbon Metropolitan Area</td>\n",
       "      <td>4267762794</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/junior-consu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Landskill</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>4190232149</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior market research Consultant</td>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Lisbon Metropolitan Area</td>\n",
       "      <td>4267770236</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/junior-marke...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Power BI/QlikSense</td>\n",
       "      <td>Fujitsu</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>4292373541</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior BI Analyst</td>\n",
       "      <td>TransPerfect</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>4268577855</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/junior-bi-an...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Landskill</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>4190233134</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Junior Healthcare Data Analyst</td>\n",
       "      <td>knokcare</td>\n",
       "      <td>Porto, Portugal</td>\n",
       "      <td>4290916404</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/junior-healt...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Irium Portugal</td>\n",
       "      <td>Alfragide, Lisbon, Portugal</td>\n",
       "      <td>4218725954</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Inetum</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>4289242209</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>Paydock</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>4281488535</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/product-anal...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title         Company  \\\n",
       "0    Junior consumer insight Analyst       NielsenIQ   \n",
       "1                     Data Scientist       Landskill   \n",
       "2  Junior market research Consultant       NielsenIQ   \n",
       "3  Data Analyst - Power BI/QlikSense         Fujitsu   \n",
       "4                  Junior BI Analyst    TransPerfect   \n",
       "5                   Business Analyst       Landskill   \n",
       "6     Junior Healthcare Data Analyst        knokcare   \n",
       "7                       Data Analyst  Irium Portugal   \n",
       "8                       Data Analyst          Inetum   \n",
       "9                    Product Analyst         Paydock   \n",
       "\n",
       "                      Location       JobId  \\\n",
       "0     Lisbon Metropolitan Area  4267762794   \n",
       "1     Lisbon, Lisbon, Portugal  4190232149   \n",
       "2     Lisbon Metropolitan Area  4267770236   \n",
       "3                     Portugal  4292373541   \n",
       "4             Lisbon, Portugal  4268577855   \n",
       "5     Lisbon, Lisbon, Portugal  4190233134   \n",
       "6              Porto, Portugal  4290916404   \n",
       "7  Alfragide, Lisbon, Portugal  4218725954   \n",
       "8             Lisbon, Portugal  4289242209   \n",
       "9                     Portugal  4281488535   \n",
       "\n",
       "                                              JobUrl SeniorityLevel  \n",
       "0  https://pt.linkedin.com/jobs/view/junior-consu...           None  \n",
       "1  https://pt.linkedin.com/jobs/view/data-scienti...           None  \n",
       "2  https://pt.linkedin.com/jobs/view/junior-marke...           None  \n",
       "3  https://pt.linkedin.com/jobs/view/data-analyst...           None  \n",
       "4  https://pt.linkedin.com/jobs/view/junior-bi-an...           None  \n",
       "5  https://pt.linkedin.com/jobs/view/business-ana...           None  \n",
       "6  https://pt.linkedin.com/jobs/view/junior-healt...           None  \n",
       "7  https://pt.linkedin.com/jobs/view/data-analyst...           None  \n",
       "8  https://pt.linkedin.com/jobs/view/data-analyst...           None  \n",
       "9  https://pt.linkedin.com/jobs/view/product-anal...           None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "keywords = 'data analysis'\n",
    "country = 'Portugal'\n",
    "\n",
    "results_country = scrape_linkedin_job_search(\n",
    "    keywords,\n",
    "    num_pages=3,      # up to 3 pages\n",
    "    country=country,  # country filter\n",
    "    pause=1.5,\n",
    "    timeout=12,\n",
    ")\n",
    "\n",
    "print(f\"Country: {country} | Total rows: {len(results_country)}\")\n",
    "results_country.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 3 days | Country: Portugal | Total rows: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobId</th>\n",
       "      <th>JobUrl</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior BI Analyst</td>\n",
       "      <td>TransPerfect</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>4268577855</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/junior-bi-an...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst (Portugal)</td>\n",
       "      <td>Cleerly</td>\n",
       "      <td>Lisboa, Lisbon, Portugal</td>\n",
       "      <td>4138246067</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/analyst-port...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Process &amp; Business Improvement</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>4268550490</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/process-busi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data &amp; Business Analyst</td>\n",
       "      <td>LUZA Group</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>4294203406</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finance and Business Analyst, Supply Chain</td>\n",
       "      <td>Bose Corporation</td>\n",
       "      <td>Lisboa, Lisbon, Portugal</td>\n",
       "      <td>4281062468</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/finance-and-...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Power BI Specialist</td>\n",
       "      <td>Adentis Portugal</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>4290869610</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/power-bi-spe...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst - Junior e Mid</td>\n",
       "      <td>Irium Portugal</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>4294148261</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>emagine - Portugal</td>\n",
       "      <td>Lisbon Metropolitan Area</td>\n",
       "      <td>4292787356</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>TENDAM</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>4291761439</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Decskill</td>\n",
       "      <td>Lisbon Metropolitan Area</td>\n",
       "      <td>4291762839</td>\n",
       "      <td>https://pt.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title             Company  \\\n",
       "0                           Junior BI Analyst        TransPerfect   \n",
       "1                          Analyst (Portugal)             Cleerly   \n",
       "2              Process & Business Improvement              Airbus   \n",
       "3              Senior Data & Business Analyst          LUZA Group   \n",
       "4  Finance and Business Analyst, Supply Chain    Bose Corporation   \n",
       "5                         Power BI Specialist    Adentis Portugal   \n",
       "6             Business Analyst - Junior e Mid      Irium Portugal   \n",
       "7                            Business Analyst  emagine - Portugal   \n",
       "8                            Business Analyst              TENDAM   \n",
       "9                                Data Analyst            Decskill   \n",
       "\n",
       "                   Location       JobId  \\\n",
       "0          Lisbon, Portugal  4268577855   \n",
       "1  Lisboa, Lisbon, Portugal  4138246067   \n",
       "2  Lisbon, Lisbon, Portugal  4268550490   \n",
       "3  Lisbon, Lisbon, Portugal  4294203406   \n",
       "4  Lisboa, Lisbon, Portugal  4281062468   \n",
       "5          Lisbon, Portugal  4290869610   \n",
       "6  Lisbon, Lisbon, Portugal  4294148261   \n",
       "7  Lisbon Metropolitan Area  4292787356   \n",
       "8          Lisbon, Portugal  4291761439   \n",
       "9  Lisbon Metropolitan Area  4291762839   \n",
       "\n",
       "                                              JobUrl SeniorityLevel  \n",
       "0  https://pt.linkedin.com/jobs/view/junior-bi-an...           None  \n",
       "1  https://pt.linkedin.com/jobs/view/analyst-port...           None  \n",
       "2  https://pt.linkedin.com/jobs/view/process-busi...           None  \n",
       "3  https://pt.linkedin.com/jobs/view/senior-data-...           None  \n",
       "4  https://pt.linkedin.com/jobs/view/finance-and-...           None  \n",
       "5  https://pt.linkedin.com/jobs/view/power-bi-spe...           None  \n",
       "6  https://pt.linkedin.com/jobs/view/business-ana...           None  \n",
       "7  https://pt.linkedin.com/jobs/view/business-ana...           None  \n",
       "8  https://pt.linkedin.com/jobs/view/business-ana...           None  \n",
       "9  https://pt.linkedin.com/jobs/view/data-analyst...           None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "keywords = 'data analysis'\n",
    "country = 'Portugal'\n",
    "num_days = 3          # last 3 days\n",
    "\n",
    "results_recent = scrape_linkedin_job_search(\n",
    "    keywords,\n",
    "    num_pages=3,\n",
    "    country=country,\n",
    "    num_days=num_days,\n",
    "    pause=1.5,\n",
    "    timeout=12,\n",
    ")\n",
    "\n",
    "print(f\"Last {num_days} days | Country: {country} | Total rows: {len(results_recent)}\")\n",
    "results_recent.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "keywords = 'data analysis'\n",
    "country = 'Portugal'\n",
    "\n",
    "results_with_seniority = scrape_linkedin_job_search(\n",
    "    keywords,\n",
    "    num_pages=2,\n",
    "    country=country,\n",
    "    num_days=3,\n",
    "    fetch_seniority=True,\n",
    "    pause=1.5,\n",
    "    per_job_pause=0.8,\n",
    "    timeout=12,\n",
    ")\n",
    "\n",
    "print(f\"Rows with attempted seniority: {len(results_with_seniority)}\")\n",
    "# Show only rows where we actually captured a SeniorityLevel (if any)\n",
    "results_with_seniority[results_with_seniority['SeniorityLevel'].notna()].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
